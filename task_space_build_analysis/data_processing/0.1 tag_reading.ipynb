{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 'PostTypeId',\n",
    "1 'AcceptedAnswerId',\n",
    "2 'CreationDate',\n",
    "3 'Score',\n",
    "4 'ViewCount',\n",
    "5 'OwnerUserId',\n",
    "6 'LastActivityDate',\n",
    "7 'Tags',\n",
    "8 'CommentCount',\n",
    "9 'AnswerCount',\n",
    "10 'ParentId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# question - all so tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python的qa的user 在 所有的数据上的 question和answer的tag\n",
    "import jsonlines\n",
    "import random\n",
    "from pickle_file import load_obj, save_obj\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "data_path = 'data_files/task_space_data/'\n",
    "data_path_save = data_path + 'obj_tag_question_bipartite_core_space/'\n",
    "\n",
    "question_answer_list = {}\n",
    "q_tags_bool = {}\n",
    "with jsonlines.open(f'{data_path}all_so_posts.json', 'r') as fcc_file:\n",
    "    for line in tqdm(fcc_file):\n",
    "        k = list(line.keys())[0]\n",
    "        v = list(line.values())[0]\n",
    "        q_tags_bool[k] = False\n",
    "        ##! 限制条件\n",
    "        if v[0] == '1' and len(k) > 0 and len(v[5]) > 0:\n",
    "            question_answer_list[k] = []\n",
    "            q_tags_bool[k] = True\n",
    "\n",
    "fcc_file.close()\n",
    "\n",
    "\n",
    "with jsonlines.open(f'{data_path}all_so_posts.json', 'r') as fcc_file:\n",
    "    for line in tqdm(fcc_file):\n",
    "        k = list(line.keys())[0]\n",
    "        v = list(line.values())[0]\n",
    "\n",
    "        if v[0] == '2' and len(k) > 0 and len(v[5]) > 0 and len(v[10]) > 0 and q_tags_bool[v[10]]:\n",
    "            question_answer_list[v[10]].append(k)\n",
    "\n",
    "fcc_file.close()\n",
    "\n",
    "\n",
    "tag_rename_dict = load_obj('tag_rename_dict', data_path_save)\n",
    "tagset_all = load_obj('tagset_all', data_path_save)\n",
    "\n",
    "with jsonlines.open(f'{data_path}all_question_so_tags.json', 'w') as w:\n",
    "    with jsonlines.open(f'{data_path}all_so_posts.json', 'r') as fcc_file:\n",
    "        for line in tqdm(fcc_file):\n",
    "            k = list(line.keys())[0]\n",
    "            v = list(line.values())[0]\n",
    "            if q_tags_bool[k]:\n",
    "                tag_list_temp1 = v[7].lstrip('<').rstrip('>').split('><')\n",
    "                tag_list_temp = [t.lower().replace('-','_') for t in tag_list_temp1]\n",
    "                tag_set = set([t for t in tag_list_temp if tag_rename_dict.get(t) is None] + [tag_rename_dict[t] for t in tag_list_temp if tag_rename_dict.get(t) is not None]).intersection(tagset_all)\n",
    "                if len(tag_set) > 0:\n",
    "                    w.write({k:[list(tag_set), v[5], v[2], question_answer_list[k]]})\n",
    "\n",
    "fcc_file.close()\n",
    "\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# answer - all so tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python的qa的user 在 所有的数据上的 question和answer的tag\n",
    "import jsonlines\n",
    "import random\n",
    "from pickle_file import load_obj, save_obj\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "data_path = 'data_files/task_space_data/'\n",
    "data_path_save = data_path + 'obj_tag_question_bipartite_core_space/'\n",
    "\n",
    "##! 初始化\n",
    "answer_date = {}\n",
    "answer_user = {}\n",
    "\n",
    "with jsonlines.open(f'{data_path}all_so_posts.json', 'r') as fcc_file:\n",
    "    for line in tqdm(fcc_file):\n",
    "        k = list(line.keys())[0]\n",
    "        v = list(line.values())[0]\n",
    "        if v[0] == '2' and len(k) > 0 and len(v[5]) > 0 and len(v[10]) > 0:\n",
    "            answer_date[k] = v[2]\n",
    "            answer_user[k] = v[5]\n",
    "\n",
    "fcc_file.close()\n",
    "\n",
    "##! 存储answer json文件\n",
    "with jsonlines.open(f'{data_path}all_question_so_tags.json', 'r') as fcc:\n",
    "    with jsonlines.open(f'{data_path}all_answer_so_tags.json', 'w') as w:\n",
    "        for line in tqdm(fcc):\n",
    "            k = list(line.keys())[0]\n",
    "            v = list(line.values())[0]\n",
    "            for ka in v[3]:\n",
    "                w.write({ka:[v[0], answer_user[ka], answer_date[ka], k]})\n",
    "                \n",
    "    w.close()\n",
    "fcc.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "##! question\n",
    "import jsonlines\n",
    "import random\n",
    "from pickle_file import load_obj, save_obj\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "data_path = 'data_files/task_space_data/'\n",
    "data_path_save = data_path + 'obj_tag_question_bipartite_core_space/'\n",
    "\n",
    "for yr in range(2008,2024):\n",
    "    y = str(yr)\n",
    "    with jsonlines.open(f'{data_path}all_question_so_tags.json', 'r') as fcc:\n",
    "        with jsonlines.open(f'{data_path}all_question_so_tags_{yr}.json', 'w') as w:\n",
    "            for line in tqdm(fcc):\n",
    "                k = list(line.keys())[0]\n",
    "                v = list(line.values())[0]\n",
    "                if v[2][:4] == y:\n",
    "                    w.write({k:v})\n",
    "                    \n",
    "        w.close()\n",
    "    fcc.close()\n",
    "\n",
    "\n",
    "\n",
    "##! answer\n",
    "for yr in range(2008,2024):\n",
    "    y = str(yr)\n",
    "    with jsonlines.open(f'{data_path}all_answer_so_tags.json', 'r') as fcc:\n",
    "        with jsonlines.open(f'{data_path}all_answer_so_tags_{yr}.json', 'w') as w:\n",
    "            for line in tqdm(fcc):\n",
    "                k = list(line.keys())[0]\n",
    "                v = list(line.values())[0]\n",
    "                if v[2][:4] == y:\n",
    "                    w.write({k:v})\n",
    "                    \n",
    "        w.close()\n",
    "    fcc.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tag count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23234009it [01:12, 319743.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from pickle_file import load_obj, save_obj\n",
    "import json\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import jsonlines\n",
    "\n",
    "data_path = 'data_files/task_space_data/'\n",
    "data_path_save = data_path + 'obj_tag_question_bipartite_core_space/'\n",
    "\n",
    "tag_list = []\n",
    "\n",
    "with jsonlines.open(f'{data_path}all_question_so_tags.json', 'r') as fcc_file:\n",
    "    for line in tqdm(fcc_file):\n",
    "        k = list(line.keys())[0]\n",
    "        v = list(line.values())[0]\n",
    "        tag_list += v[0]\n",
    "\n",
    "fcc_file.close()\n",
    "\n",
    "from collections import Counter\n",
    "tag_count_temp = dict(Counter(tag_list))\n",
    "tag_count = sorted(tag_count_temp.items(), key = lambda kv:(-kv[1], kv[0]))\n",
    "\n",
    "save_obj(tag_count,'tag_count_all', data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle_file import load_obj, save_obj\n",
    "import json\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import jsonlines\n",
    "\n",
    "data_path = 'data_files/task_space_data/'\n",
    "data_path_save = data_path + 'obj_tag_question_bipartite_core_space/'\n",
    "\n",
    "tag_count = load_obj('tag_count_all', data_path)\n",
    "tag_list = [t[0] for t in tag_count]\n",
    "\n",
    "save_obj(tag_list,'tag_list_all', data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# user list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23234009it [01:14, 311894.77it/s]\n",
      "33756964it [01:53, 298286.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# python的qa的user 在 所有的数据上的 question和answer的tag\n",
    "import jsonlines\n",
    "import random\n",
    "from pickle_file import load_obj, save_obj\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "data_path = 'data_files/task_space_data/'\n",
    "data_path_save = data_path + 'obj_tag_question_bipartite_core_space/'\n",
    "\n",
    "question_user = {str(yr):[] for yr in range(2008,2024)}\n",
    "answer_user = {str(yr):[] for yr in range(2008,2024)}\n",
    "\n",
    "with jsonlines.open(f'{data_path}all_question_so_tags.json', 'r') as fcc_file:\n",
    "    for line in tqdm(fcc_file):\n",
    "        k = list(line.keys())[0]\n",
    "        v = list(line.values())[0]\n",
    "        question_user[v[2][:4]].append(v[1])\n",
    "        \n",
    "fcc_file.close()\n",
    "\n",
    "with jsonlines.open(f'{data_path}all_answer_so_tags.json', 'r') as fcc_file:\n",
    "    for line in tqdm(fcc_file):\n",
    "        k = list(line.keys())[0]\n",
    "        v = list(line.values())[0]\n",
    "        answer_user[v[2][:4]].append(v[1])\n",
    "\n",
    "fcc_file.close()\n",
    "\n",
    "question_user_temp = {yr:set(ul) for yr, ul in question_user.items()}\n",
    "answer_user_temp = {yr:set(ul) for yr, ul in answer_user.items()}\n",
    "\n",
    "save_obj(question_user_temp, 'question_user_by_year', data_path)\n",
    "save_obj(answer_user_temp, 'answer_user_by_year', data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23234009it [01:15, 307011.32it/s]\n",
      "33756964it [01:45, 319534.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# python的qa的user 在 所有的数据上的 question和answer的tag\n",
    "import jsonlines\n",
    "import random\n",
    "from pickle_file import load_obj, save_obj\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "data_path = 'data_files/task_space_data/'\n",
    "data_path_save = data_path + 'obj_tag_question_bipartite_core_space/'\n",
    "\n",
    "question_list = {str(yr):[] for yr in range(2008,2024)}\n",
    "answer_list = {str(yr):[] for yr in range(2008,2024)}\n",
    "\n",
    "with jsonlines.open(f'{data_path}all_question_so_tags.json', 'r') as fcc_file:\n",
    "    for line in tqdm(fcc_file):\n",
    "        k = list(line.keys())[0]\n",
    "        v = list(line.values())[0]\n",
    "        question_list[v[2][:4]].append(k)\n",
    "        \n",
    "fcc_file.close()\n",
    "\n",
    "with jsonlines.open(f'{data_path}all_answer_so_tags.json', 'r') as fcc_file:\n",
    "    for line in tqdm(fcc_file):\n",
    "        k = list(line.keys())[0]\n",
    "        v = list(line.values())[0]\n",
    "        answer_list[v[2][:4]].append(k)\n",
    "\n",
    "fcc_file.close()\n",
    "\n",
    "save_obj(question_list, 'question_list_by_year', data_path)\n",
    "save_obj(answer_list, 'answer_list_by_year', data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# question and answer bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:09<00:00,  1.67it/s]\n",
      "100%|██████████| 16/16 [00:12<00:00,  1.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# python的qa的user 在 所有的数据上的 question和answer的tag\n",
    "import jsonlines\n",
    "import random\n",
    "from pickle_file import load_obj, save_obj\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "data_path = 'data_files/task_space_data/'\n",
    "data_path_save = data_path + 'obj_tag_question_bipartite_core_space/'\n",
    "\n",
    "question_list = load_obj('question_list_by_year', data_path)\n",
    "answer_list = load_obj('answer_list_by_year', data_path)\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "question_bool = defaultdict(bool)\n",
    "\n",
    "for ql in tqdm(list(question_list.values())):\n",
    "    for q in ql:\n",
    "        question_bool[q] = True\n",
    "\n",
    "\n",
    "answer_bool = defaultdict(bool)\n",
    "\n",
    "for ql in tqdm(list(answer_list.values())):\n",
    "    for q in ql:\n",
    "        answer_bool[q] = True\n",
    "\n",
    "save_obj(question_bool, 'question_bool_dict', data_path)\n",
    "save_obj(answer_bool, 'answer_bool_dict', data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# question_answer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23234009it [01:29, 258379.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# python的qa的user 在 所有的数据上的 question和answer的tag\n",
    "import jsonlines\n",
    "import random\n",
    "from pickle_file import load_obj, save_obj\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "data_path = 'data_files/task_space_data/'\n",
    "data_path_save = data_path + 'obj_tag_question_bipartite_core_space/'\n",
    "\n",
    "question_answer_list = {}\n",
    "\n",
    "with jsonlines.open(f'{data_path}all_question_so_tags.json', 'r') as fcc_file:\n",
    "    for line in tqdm(fcc_file):\n",
    "        k = list(line.keys())[0]\n",
    "        v = list(line.values())[0]\n",
    "        question_answer_list[k] = len(v[3])\n",
    "\n",
    "fcc_file.close()\n",
    "\n",
    "save_obj(question_answer_list, 'question_answer_list', data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33756964it [02:17, 245313.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# python的qa的user 在 所有的数据上的 question和answer的tag\n",
    "import jsonlines\n",
    "import random\n",
    "from pickle_file import load_obj, save_obj\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "data_path = 'data_files/task_space_data/'\n",
    "data_path_save = data_path + 'obj_tag_question_bipartite_core_space/'\n",
    "\n",
    "answer_question_dict = {}\n",
    "\n",
    "with jsonlines.open(f'{data_path}all_answer_so_tags.json', 'r') as fcc_file:\n",
    "    for line in tqdm(fcc_file):\n",
    "        k = list(line.keys())[0]\n",
    "        v = list(line.values())[0]\n",
    "        answer_question_dict[k] = v[3]\n",
    "\n",
    "fcc_file.close()\n",
    "\n",
    "save_obj(answer_question_dict, 'answer_question_dict', data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# question date and answer date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23234009it [01:22, 281188.61it/s]\n",
      "33756964it [02:02, 275543.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# python的qa的user 在 所有的数据上的 question和answer的tag\n",
    "import jsonlines\n",
    "import random\n",
    "from pickle_file import load_obj, save_obj\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "data_path = 'data_files/task_space_data/'\n",
    "data_path_save = data_path + 'obj_tag_question_bipartite_core_space/'\n",
    "\n",
    "question_date = {}\n",
    "\n",
    "with jsonlines.open(f'{data_path}all_question_so_tags.json', 'r') as fcc_file:\n",
    "    for line in tqdm(fcc_file):\n",
    "        k = list(line.keys())[0]\n",
    "        v = list(line.values())[0]\n",
    "        question_date[k] = v[2]\n",
    "\n",
    "fcc_file.close()\n",
    "\n",
    "save_obj(question_date, 'question_date', data_path)\n",
    "\n",
    "del question_date\n",
    "\n",
    "answer_date = {}\n",
    "\n",
    "with jsonlines.open(f'{data_path}all_answer_so_tags.json', 'r') as fcc_file:\n",
    "    for line in tqdm(fcc_file):\n",
    "        k = list(line.keys())[0]\n",
    "        v = list(line.values())[0]\n",
    "        answer_date[k] = v[2]\n",
    "\n",
    "fcc_file.close()\n",
    "\n",
    "save_obj(answer_date, 'answer_date', data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# user answer time hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "184951it [00:00, 288107.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "813876it [00:02, 282235.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1405143it [00:05, 277893.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2197201it [00:07, 275265.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2739530it [00:09, 274251.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3205909it [00:11, 275408.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3093186it [00:11, 271108.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3039035it [00:11, 253463.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2969988it [00:11, 259039.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2797056it [00:11, 236994.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2458635it [00:09, 253848.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2319577it [00:09, 237500.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2361830it [00:11, 198221.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1939169it [00:10, 181747.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1695331it [00:08, 208118.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "536547it [00:02, 235558.56it/s]\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "import random\n",
    "from pickle_file import load_obj, save_obj\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "data_path = 'data_files/task_space_data/'\n",
    "data_path_save = data_path + 'obj_tag_question_bipartite_core_space/'\n",
    "\n",
    "so_year_list = [yr for yr in range(2008,2024)]\n",
    "user_answer_time = {}\n",
    "\n",
    "for yr in so_year_list:\n",
    "    print(yr)\n",
    "    with jsonlines.open(f'{data_path}all_answer_so_tags_{str(yr)}.json', 'r') as fcc_file:\n",
    "        for line in tqdm(fcc_file):\n",
    "            v = list(line.values())[0]\n",
    "            if user_answer_time.get(v[1]) is None:\n",
    "                user_answer_time[v[1]] = [0 for h in range(24)]\n",
    "\n",
    "            user_answer_time[v[1]][int(v[2][11:13])] += 1\n",
    "\n",
    "    fcc_file.close()\n",
    "\n",
    "save_obj(user_answer_time,'user_answer_time_hour', data_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stack_overflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
