{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================= user sample =================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/CSH/stack_overflow/task_space_data/obj_tag_question_bipartite_core_space/vote_regression_together/user_c_l_list/user_answer_history_single_year_2008.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 31\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m================================= user sample =================================\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#sample_half_user_bool, threshold_user_bool = sample_from_users(year_bool, data_path_save, sample_percent, sample_threshold)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m##! sample_half_user_bool: 至少10个answer的user中的一半\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m \n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m##! all user bool\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m all_answer_user_bool \u001b[38;5;241m=\u001b[39m \u001b[43mget_all_user_bool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path_save\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manswer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m save_obj(all_answer_user_bool, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_answer_user_bool\u001b[39m\u001b[38;5;124m'\u001b[39m, data_path_save \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvote_regression_together/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\CSH\\stack_overflow\\task_space\\tag_question_bipartite_core_space\\task_prediction.py:41\u001b[0m, in \u001b[0;36mget_all_user_bool\u001b[1;34m(data_path_save, qa)\u001b[0m\n\u001b[0;32m     39\u001b[0m all_answer_user_bool_dict \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m yr \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2008\u001b[39m,\u001b[38;5;241m2024\u001b[39m)):\n\u001b[1;32m---> 41\u001b[0m     user_answer_history \u001b[38;5;241m=\u001b[39m \u001b[43mload_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mqa\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_history_single_year_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43myr\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mdata_path_save\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvote_regression_together/user_c_l_list/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m user_answer_history\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m     43\u001b[0m         all_answer_user_bool_dict[u] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\CSH\\stack_overflow\\task_space\\tag_question_bipartite_core_space\\pickle_file.py:11\u001b[0m, in \u001b[0;36mload_obj\u001b[1;34m(name, data_path_load)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_obj\u001b[39m(name, data_path_load \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobj/\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_path_load\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/CSH/stack_overflow/task_space_data/obj_tag_question_bipartite_core_space/vote_regression_together/user_c_l_list/user_answer_history_single_year_2008.pkl'"
     ]
    }
   ],
   "source": [
    "from pickle_file import load_obj, save_obj\n",
    "import importlib\n",
    "import task_prediction #import the module here, so that it can be reloaded.\n",
    "importlib.reload(task_prediction)\n",
    "from task_prediction import *\n",
    "\n",
    "data_path = 'data_files/task_space_data/'\n",
    "data_path_save = data_path + 'obj_tag_question_bipartite_core_space/'\n",
    "\n",
    "\n",
    "##! label\n",
    "level = 1\n",
    "sample_percent = 0.5\n",
    "sample_threshold = 10\n",
    "\n",
    "##! build community colocation matrix\n",
    "year_bool = {str(yr):False for yr in range(2008, 2024)}\n",
    "for yr in range(2008,2024):\n",
    "    year_bool[str(yr)] = True\n",
    "\n",
    "print('================================= user sample =================================')\n",
    "#sample_half_user_bool, threshold_user_bool = sample_from_users(year_bool, data_path_save, sample_percent, sample_threshold)\n",
    "\n",
    "##! sample_half_user_bool: 至少10个answer的user中的一半\n",
    "##! threshold_user_bool: 至少10个answer的user\n",
    "#save_obj(sample_half_user_bool, 'half_user_bool', data_path_save + f'vote_regression_together/')\n",
    "#save_obj(threshold_user_bool, 'all_threshold_user_bool', data_path_save + f'vote_regression_together/')\n",
    "\n",
    "##! all user bool\n",
    "#all_answer_user_bool = get_all_user_bool(data_path_save, 'answer')\n",
    "#save_obj(all_answer_user_bool, 'all_answer_user_bool', data_path_save + f'vote_regression_together/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# task density - half sample user "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import task_prediction #import the module here, so that it can be reloaded.\n",
    "importlib.reload(task_prediction)\n",
    "from task_prediction import *\n",
    "\n",
    "data_path = 'data_files/task_space_data/'\n",
    "data_path_save = data_path + 'obj_tag_question_bipartite_core_space/'\n",
    "\n",
    "\n",
    "\n",
    "##! label\n",
    "user_bool = load_obj('half_user_bool', data_path_save + f'vote_regression_together/')\n",
    "\n",
    "for level in [1,2,3]:\n",
    "\n",
    "    ##! load network and community\n",
    "    community_list_core_std = load_obj(f\"community_list_std_core_cut_level{level}\", data_path_save + 'networks/probability/')\n",
    "\n",
    "    ##! build community colocation matrix\n",
    "    print('================================= all years user community vector =================================')\n",
    "    year_bool = {str(yr):False for yr in range(2008, 2024)}\n",
    "    for yr in range(2008,2024):\n",
    "        year_bool[str(yr)] = True\n",
    "\n",
    "    user_community_set,  user_community_vector_binary = get_user_community_set_from_sample(year_bool, user_bool, data_path_save, community_list_core_std, level)\n",
    "    cc_pmi, cc_pmi_matrix, Q = build_community_cooccurrence(user_community_set, community_list_core_std, 1/len(community_list_core_std))\n",
    "    save_obj(cc_pmi, f'cc_pmi_half_user_2008_2023_level_{level}', data_path_save + f'vote_regression_together/user_task_collection/')\n",
    "    save_obj(cc_pmi_matrix, f'cc_pmi_matrix_normalized_half_user_2008_2023_level_{level}', data_path_save + f'vote_regression_together/user_task_collection/')\n",
    "    del user_community_set\n",
    "    del user_community_vector_binary\n",
    "\n",
    "\n",
    "    ##! 2008 - 2012, build community colocation matrix\n",
    "    print('=================================2008 to 2012 user community vector =================================')\n",
    "    year_bool = {str(yr):False for yr in range(2008, 2024)}\n",
    "    for yr in range(2008,2013):\n",
    "        year_bool[str(yr)] = True\n",
    "\n",
    "    user_community_set,  user_community_vector_binary = get_user_community_set_from_sample(year_bool, user_bool, data_path_save, community_list_core_std, level)\n",
    "    cc_pmi, cc_pmi_matrix, Q = build_community_cooccurrence(user_community_set, community_list_core_std, 1/len(community_list_core_std))\n",
    "    save_obj(cc_pmi, f'cc_pmi_half_user_2008_2012_level_{level}', data_path_save + f'vote_regression_together/user_task_collection/')\n",
    "    save_obj(cc_pmi_matrix, f'cc_pmi_matrix_normalized_half_user_2008_2012_level_{level}', data_path_save + f'vote_regression_together/user_task_collection/')\n",
    "    del user_community_set\n",
    "    del user_community_vector_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# task density - all threshold user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import task_prediction #import the module here, so that it can be reloaded.\n",
    "importlib.reload(task_prediction)\n",
    "from task_prediction import *\n",
    "\n",
    "data_path = 'data_files/task_space_data/'\n",
    "data_path_save = data_path + 'obj_tag_question_bipartite_core_space/'\n",
    "\n",
    "\n",
    "\n",
    "##! label\n",
    "user_bool = load_obj('all_threshold_user_bool', data_path_save + f'vote_regression_together/')\n",
    "\n",
    "for level in [1,2,3]:\n",
    "\n",
    "    ##! load network and community\n",
    "    community_list_core_std = load_obj(f\"community_list_std_core_cut_level{level}\", data_path_save + 'networks/probability/')\n",
    "    \n",
    "    ##! build community colocation matrix\n",
    "    print('================================= all years user community vector =================================')\n",
    "    year_bool = {str(yr):False for yr in range(2008, 2024)}\n",
    "    for yr in range(2008,2024):\n",
    "        year_bool[str(yr)] = True\n",
    "\n",
    "    user_community_set,  user_community_vector_binary = get_user_community_set_from_sample(year_bool, user_bool, data_path_save, community_list_core_std, level)\n",
    "    cc_pmi, cc_pmi_matrix, Q = build_community_cooccurrence(user_community_set, community_list_core_std, 1/len(community_list_core_std))\n",
    "    save_obj(cc_pmi, f'cc_pmi_all_threshold_user_2008_2023_level_{level}', data_path_save + f'vote_regression_together/user_task_collection/')\n",
    "    save_obj(cc_pmi_matrix, f'cc_pmi_matrix_normalized_all_threshold_user_2008_2023_level_{level}', data_path_save + f'vote_regression_together/user_task_collection/')\n",
    "    del user_community_set\n",
    "    del user_community_vector_binary\n",
    "\n",
    "\n",
    "    ##! 2008 - 2012, build community colocation matrix\n",
    "    print('=================================2008 to 2012 user community vector =================================')\n",
    "    year_bool = {str(yr):False for yr in range(2008, 2024)}\n",
    "    for yr in range(2008,2013):\n",
    "        year_bool[str(yr)] = True\n",
    "\n",
    "    user_community_set,  user_community_vector_binary = get_user_community_set_from_sample(year_bool, user_bool, data_path_save, community_list_core_std, level)\n",
    "    cc_pmi, cc_pmi_matrix, Q = build_community_cooccurrence(user_community_set, community_list_core_std, 1/len(community_list_core_std))\n",
    "    save_obj(cc_pmi, f'cc_pmi_all_threshold_user_2008_2012_level_{level}', data_path_save + f'vote_regression_together/user_task_collection/')\n",
    "    save_obj(cc_pmi_matrix, f'cc_pmi_matrix_normalized_all_threshold_user_2008_2012_level_{level}', data_path_save + f'vote_regression_together/user_task_collection/')\n",
    "    del user_community_set\n",
    "    del user_community_vector_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stack_overflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
