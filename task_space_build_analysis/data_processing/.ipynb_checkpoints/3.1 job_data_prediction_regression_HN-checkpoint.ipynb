{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# task predicion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T11:38:05.716686Z",
     "start_time": "2025-02-02T11:30:59.803950Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 106535/106535 [06:31<00:00, 272.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level:   1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 247/247 [00:00<00:00, 293.48it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 106535/106535 [00:07<00:00, 14536.32it/s]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import job_data_nlp_processing_gptdesp\n",
    "importlib.reload(job_data_nlp_processing_gptdesp)\n",
    "from job_data_nlp_processing_gptdesp import *\n",
    "\n",
    "data_path = 'data_files/task_space_data/'\n",
    "data_path_save = data_path + 'obj_tag_question_bipartite_core_space/'\n",
    "\n",
    "data_label = 'HN_data_gpt35'\n",
    "\n",
    "tag_count = load_obj('tag_count_all', data_path)\n",
    "tag_count_dict = {t[0]:t[1] for t in tag_count}\n",
    "\n",
    "device = 1\n",
    "job_skill_dataset = load_obj(f'job_skill_dataset', data_path_save + f'jobs/{data_label}/')\n",
    "bert_skill_embedding_gptdesp(job_skill_dataset, data_path_save, device, data_label)\n",
    "\n",
    "for level in range(1,2):\n",
    "    print('level:  ', level)\n",
    "    tag_count_bool = False\n",
    "\n",
    "    community_unweighted_level = load_obj(f\"community_core_with_cut_level{level}\", data_path_save + 'networks/probability/')\n",
    "    community_list_std = load_obj(f\"community_list_std_core_cut_level{level}\", data_path_save + 'networks/probability/')\n",
    "    \n",
    "    #{'task_id':list_c, 'tags':list_ts, 'task_description_30_words': list_30, 'task_description_20_words': list_20, 'task_description_10_words':list_10, 'task_description_5_words':list_5, 'task_description_conclude': list_conclude}\n",
    "    task_description = pd.read_csv(data_path_save + 'networks/probability/' + f'task_description_30_20_10_5_community_core_with_cut_level_{level}.csv')\n",
    "    \n",
    "    dict_task_description = pd.Series(task_description.task_description_30_words.values,index=task_description.task_id).to_dict()\n",
    "\n",
    "    bert_task_description_embedding_gptdesp(community_unweighted_level, data_path_save, device, level, data_label, dict_task_description)\n",
    "    \n",
    "    occupation_embedding_dict = load_obj(f'gptdesp_job_skill_embedding', data_path_save + f'jobs/{data_label}/')\n",
    "    occupation_task_distance_matrix_gptdesp(occupation_embedding_dict, community_unweighted_level, community_list_std, data_path_save, level, data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T13:49:58.345801Z",
     "start_time": "2025-04-02T13:47:39.329628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level:   1\n",
      "build training and target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 106535/106535 [00:10<00:00, 10078.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 47928/47928 [01:25<00:00, 558.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████| 47928/47928 [00:02<00:00, 16854.08it/s]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import job_data_nlp_processing_gptdesp\n",
    "importlib.reload(job_data_nlp_processing_gptdesp)\n",
    "from job_data_nlp_processing_gptdesp import *\n",
    "\n",
    "\n",
    "data_path = 'data_files/task_space_data/'\n",
    "data_path_save = data_path + 'obj_tag_question_bipartite_core_space/'\n",
    "\n",
    "data_label = 'HN_data_gpt35'\n",
    "\n",
    "density_user_label = 'all_threshold_user'\n",
    "\n",
    "skill_similarity_threshold = 0.3\n",
    "\n",
    "for level in range(1,2):\n",
    "    print('level:  ', level)\n",
    "    tag_count_bool = False\n",
    "\n",
    "    ##! load data\n",
    "    community_unweighted_level = load_obj(f\"community_core_with_cut_level{level}\", data_path_save + 'networks/probability/')\n",
    "    community_list_std = load_obj(f\"community_list_std_core_cut_level{level}\", data_path_save + 'networks/probability/')\n",
    "    tag_community_dict = {}\n",
    "    for i,c in community_unweighted_level.items():\n",
    "        for t in c:\n",
    "            tag_community_dict[t] = i\n",
    "\n",
    "    cc_pmi_matrix = load_obj(f'cc_pmi_matrix_normalized_{density_user_label}_2008_2023_level_{level}', data_path_save + f'vote_regression_together/user_task_collection/')\n",
    "\n",
    "    occupation_task_similarity_matrix = load_obj(f'gptdesp_job_task_similarity_matrix_level_{level}', data_path_save + f'jobs/{data_label}/')\n",
    "\n",
    "    ##! build training and target\n",
    "    print('build training and target')\n",
    "    community_list_std_no_empty = [c for c in community_list_std if len(community_unweighted_level[c]) > 0]\n",
    "    job_task_training_vector, job_task_training_set, job_task_target_set = get_job_community_set_gptdesp(occupation_task_similarity_matrix ,community_list_std, community_list_std_no_empty, skill_similarity_threshold)\n",
    "\n",
    "    #job_task_prediction = predict_user_community(cc_pmi_matrix, job_task_training_vector)\n",
    "    job_task_prediction = predict_user_community_ignore_target_gptdesp(cc_pmi_matrix, job_task_training_vector, community_list_std, job_task_target_set)\n",
    "    community_prediction, cp_all = examine_prediction_gptdesp(job_task_prediction, job_task_target_set, job_task_training_set, community_list_std)\n",
    "\n",
    "    save_obj(cp_all, f'gptdesp_cp_all_{level}', data_path_save + f'jobs/{data_label}/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# salary regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T11:50:25.323858Z",
     "start_time": "2025-02-02T11:50:01.638216Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5009/5009 [00:19<00:00, 259.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level:   1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 247/247 [00:00<00:00, 296.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 5009/5009 [00:00<00:00, 14863.29it/s]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import wage_regression_gpt_gptdesp #import the module here, so that it can be reloaded.\n",
    "importlib.reload(wage_regression_gpt_gptdesp)\n",
    "from wage_regression_gpt_gptdesp import *\n",
    "\n",
    "\n",
    "data_path = 'data_files/task_space_data/'\n",
    "data_path_save = data_path + 'obj_tag_question_bipartite_core_space/'\n",
    "\n",
    "data_label = 'HN_data_gpt35'\n",
    "\n",
    "tag_count = load_obj('tag_count_all', data_path)\n",
    "tag_count_dict = {t[0]:t[1] for t in tag_count}\n",
    "\n",
    "device = 1\n",
    "job_skill_dataset = load_obj(f'regression_job_skill_dict', data_path_save + f'jobs/{data_label}/')\n",
    "bert_skill_embedding_regression_gptdesp(job_skill_dataset, data_path_save, device, data_label)\n",
    "\n",
    "for level in range(1,2):\n",
    "    print('level:  ', level)\n",
    "    tag_count_bool = False\n",
    "\n",
    "    community_unweighted_level = load_obj(f\"community_core_with_cut_level{level}\", data_path_save + 'networks/probability/')\n",
    "    community_list_std = load_obj(f\"community_list_std_core_cut_level{level}\", data_path_save + 'networks/probability/')\n",
    "    \n",
    "    #{'task_id':list_c, 'tags':list_ts, 'task_description_30_words': list_30, 'task_description_20_words': list_20, 'task_description_10_words':list_10, 'task_description_5_words':list_5, 'task_description_conclude': list_conclude}\n",
    "    task_description = pd.read_csv(data_path_save + 'networks/probability/' + f'task_description_30_20_10_5_community_core_with_cut_level_{level}.csv')\n",
    "    \n",
    "    dict_task_description = pd.Series(task_description.task_description_30_words.values,index=task_description.task_id).to_dict()\n",
    "\n",
    "    bert_task_description_embedding_regression_gptdesp(community_unweighted_level, data_path_save, device, level, data_label, dict_task_description)\n",
    "    \n",
    "    occupation_embedding_dict = load_obj(f'gptdesp_regression_job_skill_embedding', data_path_save + f'jobs/{data_label}/')\n",
    "    occupation_task_distance_matrix_regression_gptdesp(occupation_embedding_dict, community_unweighted_level, community_list_std, data_path_save, level, data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T13:55:24.023211Z",
     "start_time": "2025-04-02T13:55:12.422552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get salary\n",
      "get task length\n",
      "get relatedness of tasks\n",
      "get task salary\n",
      "get task ubiquity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 495266/495266 [00:00<00:00, 2416837.69it/s]\n",
      "100%|██████████████████████████████████████████████████████| 487615/487615 [00:00<00:00, 2348006.86it/s]\n",
      "100%|██████████████████████████████████████████████████████| 519443/519443 [00:00<00:00, 1777699.15it/s]\n",
      "100%|██████████████████████████████████████████████████████| 467132/467132 [00:00<00:00, 1982693.36it/s]\n",
      "100%|██████████████████████████████████████████████████████| 446594/446594 [00:00<00:00, 1943522.05it/s]\n",
      "100%|██████████████████████████████████████████████████████| 192876/192876 [00:00<00:00, 1819831.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build dataframe\n",
      "gptdesp_hn_job_task_salary_only_us_log_[2018, 2019, 2020, 2021, 2022, 2023]_[2023]_df_regression_level_1_topn_300_all_threshold_user.csv\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import wage_regression_gpt_gptdesp #import the module here, so that it can be reloaded.\n",
    "importlib.reload(wage_regression_gpt_gptdesp)\n",
    "from wage_regression_gpt_gptdesp import *\n",
    "\n",
    "\n",
    "data_path = 'data_files/task_space_data/'\n",
    "data_path_save = data_path + 'obj_tag_question_bipartite_core_space/'\n",
    "\n",
    "skill_similarity_threshold = 0.3\n",
    "skill_length_threshold = 1\n",
    "\n",
    "data_label = 'HN_data_gpt35'\n",
    "density_user_label = 'all_threshold_user'\n",
    "\n",
    "##! salary year: SO 2018 to 2022, SV: 2019\n",
    "\n",
    "so_yearlist = [2018, 2019, 2020,2021,2022,2023]\n",
    "\n",
    "\n",
    "so_yearlist_salary = [2018, 2019, 2020, 2021, 2022, 2023]\n",
    "sv_yearlist_salary = [2023]\n",
    "period_label = 'hn_job_task_salary_only_us_log'\n",
    "topn = 300\n",
    "\n",
    "salary_type = 'mean'\n",
    "\n",
    "#sample_user_label = 'half_user'\n",
    "sample_user_label = 'all_threshold_user'\n",
    "#sample_user_label = 'all_answer_user'\n",
    "\n",
    "job_task_dict = {}\n",
    "\n",
    "tag_count_bool = False\n",
    "\n",
    "for level in range(1,2):\n",
    "    tag_bool_core = load_obj(f\"core_bool_with_cut_level{level}\", data_path_save + 'networks/probability/')\n",
    "    community_unweighted_level = load_obj(f\"community_core_with_cut_level{level}\", data_path_save + 'networks/probability/')\n",
    "    community_list_std = load_obj(f\"community_list_std_core_cut_level{level}\", data_path_save + 'networks/probability/')\n",
    "\n",
    "    task_salary_name = [f'{so_yearlist_salary}_{sv_yearlist_salary}_task_salary_topn_{topn}_level_{level}_{sample_user_label}', data_path_save + f'surveys/country/{period_label}/']\n",
    "\n",
    "    df = build_regression_dataframe_gptdesp(data_path_save, level, community_list_std, community_unweighted_level, skill_similarity_threshold,skill_length_threshold,so_yearlist, task_salary_name, data_label, density_user_label, salary_type)\n",
    "    df.to_csv(data_path_save + f'jobs/{data_label}/gptdesp_{period_label}_{so_yearlist_salary}_{sv_yearlist_salary}_df_regression_level_{level}_topn_{topn}_{sample_user_label}.csv')\n",
    "    \n",
    "print(f'gptdesp_{period_label}_{so_yearlist_salary}_{sv_yearlist_salary}_df_regression_level_{level}_topn_{topn}_{sample_user_label}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
